{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from config import BaseConfig\n",
    "from os.path import join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "metaphlan_abundances = pd.read_pickle(join(BaseConfig.data_dir, 'MPA.dat'))\n",
    "metaphlan_abundances.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questions for Nastya:\n",
    "1. Is MPA in -log abundances? If not - what value should we set as replacement for NaN? \n",
    "    A: No, the values are not -log.\n",
    "2. What are TaxLevel meanings?\n",
    "    A: S spicies\n",
    "3. How to use FD###_#### with FD and ConnectionID?\n",
    "    A: \n",
    "4. What is the StudyTypeID for PNP3? \n",
    "    A: 3\n",
    "5. What is the screening criteria? What and when were policy changes?\n",
    "    A: screening - no policy change\n",
    "6. What is the initial workflow? \n",
    "    few days logging in app, screening (blood tests and measurements), after 2 weeks this is T0, sample, \n",
    "    first CGM connection, first intervention in diet)\n",
    "\n",
    "7. Does the predictive algorithm save the weight? (Is the algorithm saved?) Where? How do we reach it? \n",
    "    A:  we have the predictor for every batch. the batch ID is stored at the excel. \n",
    "        BUT - we have different versions of the predictor \n",
    "        and also we switched the XGboost version somewhere in the middle.\n",
    "        \n",
    "        Each subject have a dietitian - this can be a counfounder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stool_metaphlan_df = pd.read_pickle(join(BaseConfig.data_dir, 'StoolMetadataDF.dat'))\n",
    "stool_metaphlan_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the StoolMetaphlanDF we could use the human read percentage as a proxy for shedding. Could be an interesting feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connections_df = pd.read_pickle(join(BaseConfig.data_dir, 'ConnectionsDF.dat'))\n",
    "connections_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time flow:\n",
    "1. Person starts to record lifestyle (diet, sleep, physical activity, etc.) in app. This should appear by UserID only.\n",
    "2. Several days later (~ a week) they join a study. This includes (a) screening (b) stool sample (c) CGM connection\n",
    "3. About a month later - dietery interventions. This is our treatment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question for Uri:\n",
    "1. Should we take CGM into account? As it effects the treatment. \n",
    "2. We note that users are RANDOMLY assigned to case-control (nutrition specialist - algorithm). And we might be able to get the algorithm, however nutrition specialist's reasoning for intervention is unknown to us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
